{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Sk learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import DBSCAN\n",
    "import hdbscan\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "# from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gensim\n",
    "# google_model_path= 'https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz'\n",
    "google_model_path = './GoogleNews-vectors-negative300.bin.gz'\n",
    "# Load Google's pre-trained Word2Vec model.\n",
    "# model = gensim.models.KeyedVectors.load_word2vec_format('./model/GoogleNews-vectors-negative300.bin', binary=True)  \n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(google_model_path, binary=True, limit=10 ** 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv('../jigsaw-toxic-comment-classification-challenge/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_original.copy(deep = True)\n",
    "df=df.drop(columns = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \n",
       "0        0       0       0              0  \n",
       "1        0       0       0              0  \n",
       "2        0       0       0              0  \n",
       "3        0       0       0              0  \n",
       "4        0       0       0              0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_queries = [\n",
    "#                 '@([A-Za-z0-9_]+)', #Usernames for twitter\n",
    "#                'rt\\s:\\s', #Retweets marker\n",
    "                 '(https?:\\s?\\/\\s?\\/)(\\s)?(www\\.)?(\\s?)(\\w+\\.)*([\\w\\-\\s]+\\/)*([\\w-]+)\\/?' # Hyperlinks\n",
    "                ]\n",
    "\n",
    "df['text'] = df['comment_text'].replace(regex_queries,'',regex = True)\n",
    "# Remove symbols\n",
    "df['text'].replace('[^\\w\\s]|_','', regex = True,inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>[explanation, why, the, edits, made, under, my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Daww He matches this background colour Im seem...</td>\n",
       "      <td>[daww, he, matches, this, background, colour, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man Im really not trying to edit war Its j...</td>\n",
       "      <td>[hey, man, im, really, not, trying, to, edit, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nMore\\nI cant make any real suggestions on im...</td>\n",
       "      <td>[, more, i, cant, make, any, real, suggestions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \\\n",
       "0        0       0       0              0   \n",
       "1        0       0       0              0   \n",
       "2        0       0       0              0   \n",
       "3        0       0       0              0   \n",
       "4        0       0       0              0   \n",
       "\n",
       "                                                text  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...   \n",
       "1  Daww He matches this background colour Im seem...   \n",
       "2  Hey man Im really not trying to edit war Its j...   \n",
       "3  \\nMore\\nI cant make any real suggestions on im...   \n",
       "4  You sir are my hero Any chance you remember wh...   \n",
       "\n",
       "                                      text_tokenized  \n",
       "0  [explanation, why, the, edits, made, under, my...  \n",
       "1  [daww, he, matches, this, background, colour, ...  \n",
       "2  [hey, man, im, really, not, trying, to, edit, ...  \n",
       "3  [, more, i, cant, make, any, real, suggestions...  \n",
       "4  [you, sir, are, my, hero, any, chance, you, re...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "\n",
    "df['text_tokenized'] = df['text'].apply(lambda x: tokenization(x.lower()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_nonstop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>[explanation, why, the, edits, made, under, my...</td>\n",
       "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Daww He matches this background colour Im seem...</td>\n",
       "      <td>[daww, he, matches, this, background, colour, ...</td>\n",
       "      <td>[daww, matches, background, colour, im, seemin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man Im really not trying to edit war Its j...</td>\n",
       "      <td>[hey, man, im, really, not, trying, to, edit, ...</td>\n",
       "      <td>[hey, man, im, really, trying, edit, war, guy,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nMore\\nI cant make any real suggestions on im...</td>\n",
       "      <td>[, more, i, cant, make, any, real, suggestions...</td>\n",
       "      <td>[, cant, make, real, suggestions, improvement,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n",
       "      <td>[sir, hero, chance, remember, page, thats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\nCongratulations from me as well use the to...</td>\n",
       "      <td>[, congratulations, from, me, as, well, use, t...</td>\n",
       "      <td>[, congratulations, well, use, tools, well, ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>[cocksucker, before, you, piss, around, on, my...</td>\n",
       "      <td>[cocksucker, piss, around, work]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>[your, vandalism, to, the, matt, shirvington, ...</td>\n",
       "      <td>[vandalism, matt, shirvington, article, revert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sorry if the word nonsense was offensive to yo...</td>\n",
       "      <td>[sorry, if, the, word, nonsense, was, offensiv...</td>\n",
       "      <td>[sorry, word, nonsense, offensive, anyway, im,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>[alignment, on, this, subject, and, which, are...</td>\n",
       "      <td>[alignment, subject, contrary, dulithgow]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0             0   \n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1             1   \n",
       "7  Your vandalism to the Matt Shirvington article...      0             0   \n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0             0   \n",
       "9  alignment on this subject and which are contra...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \\\n",
       "0        0       0       0              0   \n",
       "1        0       0       0              0   \n",
       "2        0       0       0              0   \n",
       "3        0       0       0              0   \n",
       "4        0       0       0              0   \n",
       "5        0       0       0              0   \n",
       "6        1       0       1              0   \n",
       "7        0       0       0              0   \n",
       "8        0       0       0              0   \n",
       "9        0       0       0              0   \n",
       "\n",
       "                                                text  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...   \n",
       "1  Daww He matches this background colour Im seem...   \n",
       "2  Hey man Im really not trying to edit war Its j...   \n",
       "3  \\nMore\\nI cant make any real suggestions on im...   \n",
       "4  You sir are my hero Any chance you remember wh...   \n",
       "5  \\n\\nCongratulations from me as well use the to...   \n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "7  Your vandalism to the Matt Shirvington article...   \n",
       "8  Sorry if the word nonsense was offensive to yo...   \n",
       "9  alignment on this subject and which are contra...   \n",
       "\n",
       "                                      text_tokenized  \\\n",
       "0  [explanation, why, the, edits, made, under, my...   \n",
       "1  [daww, he, matches, this, background, colour, ...   \n",
       "2  [hey, man, im, really, not, trying, to, edit, ...   \n",
       "3  [, more, i, cant, make, any, real, suggestions...   \n",
       "4  [you, sir, are, my, hero, any, chance, you, re...   \n",
       "5  [, congratulations, from, me, as, well, use, t...   \n",
       "6  [cocksucker, before, you, piss, around, on, my...   \n",
       "7  [your, vandalism, to, the, matt, shirvington, ...   \n",
       "8  [sorry, if, the, word, nonsense, was, offensiv...   \n",
       "9  [alignment, on, this, subject, and, which, are...   \n",
       "\n",
       "                                        text_nonstop  \n",
       "0  [explanation, edits, made, username, hardcore,...  \n",
       "1  [daww, matches, background, colour, im, seemin...  \n",
       "2  [hey, man, im, really, trying, edit, war, guy,...  \n",
       "3  [, cant, make, real, suggestions, improvement,...  \n",
       "4         [sir, hero, chance, remember, page, thats]  \n",
       "5  [, congratulations, well, use, tools, well, ta...  \n",
       "6                   [cocksucker, piss, around, work]  \n",
       "7  [vandalism, matt, shirvington, article, revert...  \n",
       "8  [sorry, word, nonsense, offensive, anyway, im,...  \n",
       "9          [alignment, subject, contrary, dulithgow]  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in stopWords]\n",
    "    return text\n",
    "    \n",
    "df['text_nonstop'] = df['text_tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "def stemming(text):\n",
    "    text = [ps.stem(word) for word in text if len(word) < 30]  # the length restriction prevents  \n",
    "                                                                # long strings from overflowing recursion used in stemmer\n",
    "    return text\n",
    "\n",
    "df['text_stemmed'] = df['text_nonstop'].apply(lambda x: stemming(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_nonstop</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>[explanation, why, the, edits, made, under, my...</td>\n",
       "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
       "      <td>[explan, edit, made, usernam, hardcor, metalli...</td>\n",
       "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Daww He matches this background colour Im seem...</td>\n",
       "      <td>[daww, he, matches, this, background, colour, ...</td>\n",
       "      <td>[daww, matches, background, colour, im, seemin...</td>\n",
       "      <td>[daww, match, background, colour, im, seemingl...</td>\n",
       "      <td>[daww, match, background, colour, im, seemingl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man Im really not trying to edit war Its j...</td>\n",
       "      <td>[hey, man, im, really, not, trying, to, edit, ...</td>\n",
       "      <td>[hey, man, im, really, trying, edit, war, guy,...</td>\n",
       "      <td>[hey, man, im, realli, tri, edit, war, guy, co...</td>\n",
       "      <td>[hey, man, im, really, trying, edit, war, guy,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nMore\\nI cant make any real suggestions on im...</td>\n",
       "      <td>[, more, i, cant, make, any, real, suggestions...</td>\n",
       "      <td>[, cant, make, real, suggestions, improvement,...</td>\n",
       "      <td>[, cant, make, real, suggest, improv, wonder, ...</td>\n",
       "      <td>[, cant, make, real, suggestion, improvement, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n",
       "      <td>[sir, hero, chance, remember, page, thats]</td>\n",
       "      <td>[sir, hero, chanc, rememb, page, that]</td>\n",
       "      <td>[sir, hero, chance, remember, page, thats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\nCongratulations from me as well use the to...</td>\n",
       "      <td>[, congratulations, from, me, as, well, use, t...</td>\n",
       "      <td>[, congratulations, well, use, tools, well, ta...</td>\n",
       "      <td>[, congratul, well, use, tool, well, talk, ]</td>\n",
       "      <td>[, congratulation, well, use, tool, well, talk, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>[cocksucker, before, you, piss, around, on, my...</td>\n",
       "      <td>[cocksucker, piss, around, work]</td>\n",
       "      <td>[cocksuck, piss, around, work]</td>\n",
       "      <td>[cocksucker, piss, around, work]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>[your, vandalism, to, the, matt, shirvington, ...</td>\n",
       "      <td>[vandalism, matt, shirvington, article, revert...</td>\n",
       "      <td>[vandal, matt, shirvington, articl, revert, pl...</td>\n",
       "      <td>[vandalism, matt, shirvington, article, revert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sorry if the word nonsense was offensive to yo...</td>\n",
       "      <td>[sorry, if, the, word, nonsense, was, offensiv...</td>\n",
       "      <td>[sorry, word, nonsense, offensive, anyway, im,...</td>\n",
       "      <td>[sorri, word, nonsens, offens, anyway, im, int...</td>\n",
       "      <td>[sorry, word, nonsense, offensive, anyway, im,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>[alignment, on, this, subject, and, which, are...</td>\n",
       "      <td>[alignment, subject, contrary, dulithgow]</td>\n",
       "      <td>[align, subject, contrari, dulithgow]</td>\n",
       "      <td>[alignment, subject, contrary, dulithgow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nFair use rationale for ImageWonjujpg\\n\\nThan...</td>\n",
       "      <td>[, fair, use, rationale, for, imagewonjujpg, t...</td>\n",
       "      <td>[, fair, use, rationale, imagewonjujpg, thanks...</td>\n",
       "      <td>[, fair, use, rational, imagewonjujpg, thank, ...</td>\n",
       "      <td>[, fair, use, rationale, imagewonjujpg, thanks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bbq \\n\\nbe a man and lets discuss it-maybe ove...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bbq \\n\\nbe a man and lets discuss itmaybe over...</td>\n",
       "      <td>[bbq, be, a, man, and, lets, discuss, itmaybe,...</td>\n",
       "      <td>[bbq, man, lets, discuss, itmaybe, phone]</td>\n",
       "      <td>[bbq, man, let, discuss, itmayb, phone]</td>\n",
       "      <td>[bbq, man, let, discus, itmaybe, phone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey what is it\\n  talk \\nWhat is it an exclusi...</td>\n",
       "      <td>[hey, what, is, it, talk, what, is, it, an, ex...</td>\n",
       "      <td>[hey, talk, exclusive, group, wp, talibanswho,...</td>\n",
       "      <td>[hey, talk, exclus, group, wp, talibanswho, go...</td>\n",
       "      <td>[hey, talk, exclusive, group, wp, talibanswho,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Before you start throwing accusations and warn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Before you start throwing accusations and warn...</td>\n",
       "      <td>[before, you, start, throwing, accusations, an...</td>\n",
       "      <td>[start, throwing, accusations, warnings, lets,...</td>\n",
       "      <td>[start, throw, accus, warn, let, review, edit,...</td>\n",
       "      <td>[start, throwing, accusation, warning, let, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Oh, and the girl above started her arguments w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh and the girl above started her arguments wi...</td>\n",
       "      <td>[oh, and, the, girl, above, started, her, argu...</td>\n",
       "      <td>[oh, girl, started, arguments, stuck, nose, do...</td>\n",
       "      <td>[oh, girl, start, argument, stuck, nose, doesn...</td>\n",
       "      <td>[oh, girl, started, argument, stuck, nose, doe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\nJuelz Santanas Age\\n\\nIn 2002 Juelz Santan...</td>\n",
       "      <td>[, juelz, santanas, age, in, 2002, juelz, sant...</td>\n",
       "      <td>[, juelz, santanas, age, 2002, juelz, santana,...</td>\n",
       "      <td>[, juelz, santana, age, 2002, juelz, santana, ...</td>\n",
       "      <td>[, juelz, santanas, age, 2002, juelz, santana,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bye \\n\\nDont look come or think of comming bac...</td>\n",
       "      <td>[bye, dont, look, come, or, think, of, comming...</td>\n",
       "      <td>[bye, dont, look, come, think, comming, back, ...</td>\n",
       "      <td>[bye, dont, look, come, think, com, back, tosser]</td>\n",
       "      <td>[bye, dont, look, come, think, comming, back, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>REDIRECT TalkVoydan Pop Georgiev Chernodrinski</td>\n",
       "      <td>[redirect, talkvoydan, pop, georgiev, chernodr...</td>\n",
       "      <td>[redirect, talkvoydan, pop, georgiev, chernodr...</td>\n",
       "      <td>[redirect, talkvoydan, pop, georgiev, chernodr...</td>\n",
       "      <td>[redirect, talkvoydan, pop, georgiev, chernodr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The Mitsurugi point made no sense - why not ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The Mitsurugi point made no sense  why not arg...</td>\n",
       "      <td>[the, mitsurugi, point, made, no, sense, why, ...</td>\n",
       "      <td>[mitsurugi, point, made, sense, argue, include...</td>\n",
       "      <td>[mitsurugi, point, made, sens, argu, includ, h...</td>\n",
       "      <td>[mitsurugi, point, made, sense, argue, include...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Don't mean to bother you \\n\\nI see that you're...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Dont mean to bother you \\n\\nI see that youre w...</td>\n",
       "      <td>[dont, mean, to, bother, you, i, see, that, yo...</td>\n",
       "      <td>[dont, mean, bother, see, youre, writing, some...</td>\n",
       "      <td>[dont, mean, bother, see, your, write, someth,...</td>\n",
       "      <td>[dont, mean, bother, see, youre, writing, some...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         comment_text  toxic  severe_toxic  \\\n",
       "0   Explanation\\nWhy the edits made under my usern...      0             0   \n",
       "1   D'aww! He matches this background colour I'm s...      0             0   \n",
       "2   Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3   \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n",
       "4   You, sir, are my hero. Any chance you remember...      0             0   \n",
       "5   \"\\n\\nCongratulations from me as well, use the ...      0             0   \n",
       "6        COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1             1   \n",
       "7   Your vandalism to the Matt Shirvington article...      0             0   \n",
       "8   Sorry if the word 'nonsense' was offensive to ...      0             0   \n",
       "9   alignment on this subject and which are contra...      0             0   \n",
       "10  \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...      0             0   \n",
       "11  bbq \\n\\nbe a man and lets discuss it-maybe ove...      0             0   \n",
       "12  Hey... what is it..\\n@ | talk .\\nWhat is it......      1             0   \n",
       "13  Before you start throwing accusations and warn...      0             0   \n",
       "14  Oh, and the girl above started her arguments w...      0             0   \n",
       "15  \"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...      0             0   \n",
       "16  Bye! \\n\\nDon't look, come or think of comming ...      1             0   \n",
       "17   REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski      0             0   \n",
       "18  The Mitsurugi point made no sense - why not ar...      0             0   \n",
       "19  Don't mean to bother you \\n\\nI see that you're...      0             0   \n",
       "\n",
       "    obscene  threat  insult  identity_hate  \\\n",
       "0         0       0       0              0   \n",
       "1         0       0       0              0   \n",
       "2         0       0       0              0   \n",
       "3         0       0       0              0   \n",
       "4         0       0       0              0   \n",
       "5         0       0       0              0   \n",
       "6         1       0       1              0   \n",
       "7         0       0       0              0   \n",
       "8         0       0       0              0   \n",
       "9         0       0       0              0   \n",
       "10        0       0       0              0   \n",
       "11        0       0       0              0   \n",
       "12        0       0       0              0   \n",
       "13        0       0       0              0   \n",
       "14        0       0       0              0   \n",
       "15        0       0       0              0   \n",
       "16        0       0       0              0   \n",
       "17        0       0       0              0   \n",
       "18        0       0       0              0   \n",
       "19        0       0       0              0   \n",
       "\n",
       "                                                 text  \\\n",
       "0   Explanation\\nWhy the edits made under my usern...   \n",
       "1   Daww He matches this background colour Im seem...   \n",
       "2   Hey man Im really not trying to edit war Its j...   \n",
       "3   \\nMore\\nI cant make any real suggestions on im...   \n",
       "4   You sir are my hero Any chance you remember wh...   \n",
       "5   \\n\\nCongratulations from me as well use the to...   \n",
       "6        COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "7   Your vandalism to the Matt Shirvington article...   \n",
       "8   Sorry if the word nonsense was offensive to yo...   \n",
       "9   alignment on this subject and which are contra...   \n",
       "10  \\nFair use rationale for ImageWonjujpg\\n\\nThan...   \n",
       "11  bbq \\n\\nbe a man and lets discuss itmaybe over...   \n",
       "12  Hey what is it\\n  talk \\nWhat is it an exclusi...   \n",
       "13  Before you start throwing accusations and warn...   \n",
       "14  Oh and the girl above started her arguments wi...   \n",
       "15  \\n\\nJuelz Santanas Age\\n\\nIn 2002 Juelz Santan...   \n",
       "16  Bye \\n\\nDont look come or think of comming bac...   \n",
       "17     REDIRECT TalkVoydan Pop Georgiev Chernodrinski   \n",
       "18  The Mitsurugi point made no sense  why not arg...   \n",
       "19  Dont mean to bother you \\n\\nI see that youre w...   \n",
       "\n",
       "                                       text_tokenized  \\\n",
       "0   [explanation, why, the, edits, made, under, my...   \n",
       "1   [daww, he, matches, this, background, colour, ...   \n",
       "2   [hey, man, im, really, not, trying, to, edit, ...   \n",
       "3   [, more, i, cant, make, any, real, suggestions...   \n",
       "4   [you, sir, are, my, hero, any, chance, you, re...   \n",
       "5   [, congratulations, from, me, as, well, use, t...   \n",
       "6   [cocksucker, before, you, piss, around, on, my...   \n",
       "7   [your, vandalism, to, the, matt, shirvington, ...   \n",
       "8   [sorry, if, the, word, nonsense, was, offensiv...   \n",
       "9   [alignment, on, this, subject, and, which, are...   \n",
       "10  [, fair, use, rationale, for, imagewonjujpg, t...   \n",
       "11  [bbq, be, a, man, and, lets, discuss, itmaybe,...   \n",
       "12  [hey, what, is, it, talk, what, is, it, an, ex...   \n",
       "13  [before, you, start, throwing, accusations, an...   \n",
       "14  [oh, and, the, girl, above, started, her, argu...   \n",
       "15  [, juelz, santanas, age, in, 2002, juelz, sant...   \n",
       "16  [bye, dont, look, come, or, think, of, comming...   \n",
       "17  [redirect, talkvoydan, pop, georgiev, chernodr...   \n",
       "18  [the, mitsurugi, point, made, no, sense, why, ...   \n",
       "19  [dont, mean, to, bother, you, i, see, that, yo...   \n",
       "\n",
       "                                         text_nonstop  \\\n",
       "0   [explanation, edits, made, username, hardcore,...   \n",
       "1   [daww, matches, background, colour, im, seemin...   \n",
       "2   [hey, man, im, really, trying, edit, war, guy,...   \n",
       "3   [, cant, make, real, suggestions, improvement,...   \n",
       "4          [sir, hero, chance, remember, page, thats]   \n",
       "5   [, congratulations, well, use, tools, well, ta...   \n",
       "6                    [cocksucker, piss, around, work]   \n",
       "7   [vandalism, matt, shirvington, article, revert...   \n",
       "8   [sorry, word, nonsense, offensive, anyway, im,...   \n",
       "9           [alignment, subject, contrary, dulithgow]   \n",
       "10  [, fair, use, rationale, imagewonjujpg, thanks...   \n",
       "11          [bbq, man, lets, discuss, itmaybe, phone]   \n",
       "12  [hey, talk, exclusive, group, wp, talibanswho,...   \n",
       "13  [start, throwing, accusations, warnings, lets,...   \n",
       "14  [oh, girl, started, arguments, stuck, nose, do...   \n",
       "15  [, juelz, santanas, age, 2002, juelz, santana,...   \n",
       "16  [bye, dont, look, come, think, comming, back, ...   \n",
       "17  [redirect, talkvoydan, pop, georgiev, chernodr...   \n",
       "18  [mitsurugi, point, made, sense, argue, include...   \n",
       "19  [dont, mean, bother, see, youre, writing, some...   \n",
       "\n",
       "                                         text_stemmed  \\\n",
       "0   [explan, edit, made, usernam, hardcor, metalli...   \n",
       "1   [daww, match, background, colour, im, seemingl...   \n",
       "2   [hey, man, im, realli, tri, edit, war, guy, co...   \n",
       "3   [, cant, make, real, suggest, improv, wonder, ...   \n",
       "4              [sir, hero, chanc, rememb, page, that]   \n",
       "5        [, congratul, well, use, tool, well, talk, ]   \n",
       "6                      [cocksuck, piss, around, work]   \n",
       "7   [vandal, matt, shirvington, articl, revert, pl...   \n",
       "8   [sorri, word, nonsens, offens, anyway, im, int...   \n",
       "9               [align, subject, contrari, dulithgow]   \n",
       "10  [, fair, use, rational, imagewonjujpg, thank, ...   \n",
       "11            [bbq, man, let, discuss, itmayb, phone]   \n",
       "12  [hey, talk, exclus, group, wp, talibanswho, go...   \n",
       "13  [start, throw, accus, warn, let, review, edit,...   \n",
       "14  [oh, girl, start, argument, stuck, nose, doesn...   \n",
       "15  [, juelz, santana, age, 2002, juelz, santana, ...   \n",
       "16  [bye, dont, look, come, think, com, back, tosser]   \n",
       "17  [redirect, talkvoydan, pop, georgiev, chernodr...   \n",
       "18  [mitsurugi, point, made, sens, argu, includ, h...   \n",
       "19  [dont, mean, bother, see, your, write, someth,...   \n",
       "\n",
       "                                          text_lemmed  \n",
       "0   [explanation, edits, made, username, hardcore,...  \n",
       "1   [daww, match, background, colour, im, seemingl...  \n",
       "2   [hey, man, im, really, trying, edit, war, guy,...  \n",
       "3   [, cant, make, real, suggestion, improvement, ...  \n",
       "4          [sir, hero, chance, remember, page, thats]  \n",
       "5   [, congratulation, well, use, tool, well, talk, ]  \n",
       "6                    [cocksucker, piss, around, work]  \n",
       "7   [vandalism, matt, shirvington, article, revert...  \n",
       "8   [sorry, word, nonsense, offensive, anyway, im,...  \n",
       "9           [alignment, subject, contrary, dulithgow]  \n",
       "10  [, fair, use, rationale, imagewonjujpg, thanks...  \n",
       "11            [bbq, man, let, discus, itmaybe, phone]  \n",
       "12  [hey, talk, exclusive, group, wp, talibanswho,...  \n",
       "13  [start, throwing, accusation, warning, let, re...  \n",
       "14  [oh, girl, started, argument, stuck, nose, doe...  \n",
       "15  [, juelz, santanas, age, 2002, juelz, santana,...  \n",
       "16  [bye, dont, look, come, think, comming, back, ...  \n",
       "17  [redirect, talkvoydan, pop, georgiev, chernodr...  \n",
       "18  [mitsurugi, point, made, sense, argue, include...  \n",
       "19  [dont, mean, bother, see, youre, writing, some...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer(text):\n",
    "    text = [wn.lemmatize(word) for word in text if len(word) < 30] \n",
    "    return text\n",
    "\n",
    "df['text_lemmed'] = df['text_nonstop'].apply(lambda x: lemmatizer(x))\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Word2VecKeyedVectors' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-70539d1afac4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Word2VecKeyedVectors' object is not callable"
     ]
    }
   ],
   "source": [
    "model.wv('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'metallica' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-60f866aea9f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_vectorized'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_lemmed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvectorize_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3590\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3591\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3593\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-60f866aea9f9>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_vectorized'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_lemmed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvectorize_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-55-60f866aea9f9>\u001b[0m in \u001b[0;36mvectorize_words\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvectorize_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_vectorized'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_lemmed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvectorize_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-60f866aea9f9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvectorize_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_vectorized'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_lemmed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvectorize_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'metallica' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "def vectorize_words(text):\n",
    "        text = [model.get_vector(word) for word in text]\n",
    "        return text\n",
    "df['text_vectorized'] = df['text_lemmed'].apply(lambda x: vectorize_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text(text):\n",
    "#     text_lc = \"\".join([word.lower() for word in text if word not in string.punctuation]) # remove puntuation\n",
    "#     text_rc = re.sub('[0-9]+', '', text_lc)\n",
    "#     tokens = re.split('\\W+', text_rc)    # tokenization\n",
    "#     text = [ps.stem(word) for word in tokens if word not in stopWords and len(word) < 30]  # remove stopwords and stemming\n",
    "#     return text\n",
    "# countVectorizer = CountVectorizer(analyzer=clean_text) \n",
    "# countVector = countVectorizer.fit_transform(df['text'])\n",
    "# print('{} Number of Tweets has {} words'.format(countVector.shape[0], countVector.shape[1]))\n",
    "count_vect_df = pd.DataFrame(countVector.toarray(), columns=countVectorizer.get_feature_names())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "values not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-9eaf0731f081>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcountVector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: values not found"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df[['toxic','severe_toxic','obscene','threat','insult','identity_hate']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NN = Sequential()\n",
    "\n",
    "NN.add(Dense(100,  input_dim = X_train.shape[1])) # need feature input dim (28x28) for first hidden layer\n",
    "NN.add(Activation('relu'))\n",
    "\n",
    "NN.add(Dense(20))\n",
    "NN.add(Activation('relu'))\n",
    "\n",
    "NN.add(Dense(10)) # note we would typically use higher dim than this for last hidden layer\n",
    "NN.add(Activation('relu', name = '2D_layer')) # naming this layer so we can extract it later\n",
    "\n",
    "# Output layer\n",
    "\n",
    "NN.add(Dense(6))\n",
    "NN.add(Activation('sigmoid'))\n",
    "\n",
    "# NN.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# For multi label (Classes are not mutually exclusive)\n",
    "NN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "NN.fit(X_train, y_train, epochs=20, batch_size=512, verbose=1) # track progress as we fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
