{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "import re\n",
    "import string\n",
    "stopWords = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gensim\n",
    "google_model_path= 'https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz'\n",
    "# Load Google's pre-trained Word2Vec model.\n",
    "# model = gensim.models.KeyedVectors.load_word2vec_format('./model/GoogleNews-vectors-negative300.bin', binary=True)  \n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(google_model_path, binary=True, limit=10 ** 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_original = pd.read_csv('../OnlineHarassmentDataset/onlineHarassmentDataset.tdf',\n",
    "                          sep='\\t', \n",
    "                          lineterminator='\\r',\n",
    "                          header = 'infer', \n",
    "                          encoding='latin-1')\n",
    "df=df_original.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Code</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>@Grumpy_P_Sloth @deanesmay feminists argue for...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>1948Army of England helped the Jews to occupy ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>H</td>\n",
       "      <td>Dutch Leader Says Europe to collapse In 6 Week...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>H</td>\n",
       "      <td>RT @__DeLay: The next day the Romans and the J...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>H</td>\n",
       "      <td>RT @Bakersman_Joe: When Hitler Invited The Jew...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Code                                              Tweet  Unnamed: 3  \\\n",
       "0   1    H  @Grumpy_P_Sloth @deanesmay feminists argue for...         NaN   \n",
       "1   2    H  1948Army of England helped the Jews to occupy ...         NaN   \n",
       "2   3    H  Dutch Leader Says Europe to collapse In 6 Week...         NaN   \n",
       "3   4    H  RT @__DeLay: The next day the Romans and the J...         NaN   \n",
       "4   5    H  RT @Bakersman_Joe: When Hitler Invited The Jew...         NaN   \n",
       "\n",
       "   Unnamed: 4  Unnamed: 5  Unnamed: 6  Unnamed: 7  Unnamed: 8  Unnamed: 9  \\\n",
       "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "3         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "   Unnamed: 10  Unnamed: 11  Unnamed: 12  \n",
       "0          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harassment is 25.96% of the dataset\n"
     ]
    }
   ],
   "source": [
    "# How balanced are the classes?\n",
    "print('Harassment is ' + str(round(sum(df['Code'] == 'H')/df.shape[0],4) * 100) + '% of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality of Life renaming\n",
    "df = df[['Code','Tweet']]\n",
    "df.rename(index=str, columns={\"Code\": \"code\", \"Tweet\": \"tweet\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@azhodzic lmfaaaooooo @jeffbarnes_  you fucking nigger'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[200,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of Regex Strings to Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(lambda tweet: tweet.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_queries = [\n",
    "                 '@([A-Za-z0-9_]+)', #Usernames\n",
    "                'rt\\s:\\s', #Retweets\n",
    "                 '(https?:\\s?\\/\\s?\\/)(\\s)?(www\\.)?(\\s?)(\\w+\\.)*([\\w\\-\\s]+\\/)*([\\w-]+)\\/?' # Hyperlinks\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['tweet'].replace(regex_queries,'',regex = True, inplace = True)\n",
    "# Remove symbols, replace with spaces\n",
    "df['tweet'].replace('[^\\w\\s]|_','', regex = True,inplace = True)\n",
    "# df['tweet'].replace('/\\s+/g','', regex = True,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"@Grumpy_P_Sloth @deanesmay feminists argue for raising minimum wage cause a women's studies major needs the $15 an hour wage at her McJob.\"\n",
      " '1948Army of England helped the Jews to occupy Palestine.After that the Jews killed thousands of Englishmen and returned to England as dogs1'\n",
      " 'Dutch Leader Says Europe to collapse In 6 Weeks thnks > @BillGates, @GeorgeSoros, & @FWD_us #AltRight #WhiteGenocide https: / /t.co /rl1mh82jda'\n",
      " 'RT @__DeLay: The next day the Romans and the Jews or watever was like \"aye fuck that nigga Jesus. We riding out on his ass today https: / /t.'\n",
      " \"RT @Bakersman_Joe: When Hitler Invited The Jews To The Smoke Session But It Wasn't The Gas They Was Expecting #MemeHistory https: / /t.co /lMw\"\n",
      " 'RT @billmaher: Bravo to #Netanyahu for his 45 second glare this week at the UN! The Jews have finally done it, they weaponized guilt!'\n",
      " 'RT @BitchImKermit: White people literally Be like \" I\\'m not racist you fucking Nigger\"'\n",
      " 'RT @CharlesFinch: \"The Jews were provided free transportation directly to the camps.\" - Bill O\\'Reilly'\n",
      " 'RT @gofran942010: \"I would have killed all the jews in the world, But I kept some to show the world why I killed them\" -Hitler http: / /t.co /'\n",
      " \"RT @HeymanHustle: .. @MichelleDBeadle I can do news. I can do newspeople. And I AM news. When they say THE JEWS control the media, they're \"]\n"
     ]
    }
   ],
   "source": [
    "print(df_original['Tweet'][:10].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['  feminists argue for raising minimum wage cause a womens studies major needs the 15 an hour wage at her mcjob'\n",
      " '1948army of england helped the jews to occupy palestineafter that the jews killed thousands of englishmen and returned to england as dogs1'\n",
      " 'dutch leader says europe to collapse in 6 weeks thnks      altright whitegenocide '\n",
      " 'the next day the romans and the jews or watever was like aye fuck that nigga jesus we riding out on his ass today '\n",
      " 'when hitler invited the jews to the smoke session but it wasnt the gas they was expecting memehistory '\n",
      " 'bravo to netanyahu for his 45 second glare this week at the un the jews have finally done it they weaponized guilt'\n",
      " 'white people literally be like  im not racist you fucking nigger'\n",
      " 'the jews were provided free transportation directly to the camps  bill oreilly'\n",
      " 'i would have killed all the jews in the world but i kept some to show the world why i killed them hitler  '\n",
      " '  i can do news i can do newspeople and i am news when they say the jews control the media theyre ']\n"
     ]
    }
   ],
   "source": [
    "print(df['tweet'][:10].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"RT @HeymanHustle: .. @MichelleDBeadle I can do news. I can do newspeople. And I AM news. When they say THE JEWS control the media, they're \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original['Tweet'].iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dutch leader says europe to collapse in 6 weeks thnks      altright whitegenocide '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ff0ea16cf11d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train_cv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mX_test_cv1\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mcv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv1 = CountVectorizer(stop_words='english')\n",
    "\n",
    "X_train_cv1 = cv1.fit_transform(X_train)\n",
    "X_test_cv1  = cv1.transform(X_test)\n",
    "\n",
    "pd.DataFrame(X_train_cv1.toarray(), columns=cv1.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "data = \"dutch leader says europe to collapse in 6 weeks thnks      altright whitegenocide \"\n",
    "#stopWords = set(stopwords.words('english'))\n",
    "words = word_tokenize(data)\n",
    "wordsFiltered = []\n",
    "\n",
    "for w in words:\n",
    "    if w not in stopWords:\n",
    "        wordsFiltered.append(w)\n",
    "\n",
    "print(wordsFiltered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done already\n",
    "\n",
    "# def remove_punct(text):\n",
    "#     text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "#     text = re.sub('[0-9]+', '', text)\n",
    "#     return text\n",
    "\n",
    "# df['Tweet_punct'] = df['Tweet'].apply(lambda x: remove_punct(x))\n",
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "\n",
    "df['Tweet_tokenized'] = df['tweet'].apply(lambda x: tokenization(x.lower()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in stopWords]\n",
    "    return text\n",
    "    \n",
    "df['Tweet_nonstop'] = df['Tweet_tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming / Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "def stemming(text):\n",
    "    text = [ps.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "df['Tweet_stemmed'] = df['Tweet_nonstop'].apply(lambda x: stemming(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer(text):\n",
    "    text = [wn.lemmatize(word) for word in text]\n",
    "    return text\n",
    "\n",
    "df['Tweet_lemmatized'] = df['Tweet_nonstop'].apply(lambda x: lemmatizer(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text_lc = \"\".join([word.lower() for word in text if word not in string.punctuation]) # remove puntuation\n",
    "    text_rc = re.sub('[0-9]+', '', text_lc)\n",
    "    tokens = re.split('\\W+', text_rc)    # tokenization\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopWords]  # remove stopwords and stemming\n",
    "    return text\n",
    "countVectorizer = CountVectorizer(analyzer=clean_text) \n",
    "countVector = countVectorizer.fit_transform(df['tweet'])\n",
    "print('{} Number of tweets has {} words'.format(countVector.shape[0], countVector.shape[1]))\n",
    "#print(countVectorizer.get_feature_names())\n",
    "count_vect_df = pd.DataFrame(countVector.toarray(), columns=countVectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
